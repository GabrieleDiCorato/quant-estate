{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pipeline 3: Mapping\n",
    "\n",
    "This is a prototype and test for the third pipeline, and ETL step from ListingDetails to ListingRecord.\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Find the project root\n",
    "project_root = Path().cwd().parent\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Add project root to Python path (not just sources)\n",
    "sys.path.insert(0, str(project_root))\n",
    "print(f\"Added to Python path: {project_root}\")\n",
    "\n",
    "# Set environment variables\n",
    "\n",
    "os.environ[\"QE_ENV\"] = \"dev\"\n",
    "os.environ[\"QE_CONF_FOLDER\"] = \"sources/resources\"\n",
    "print(f\"Added environment variables: QE_ENV={os.environ['QE_ENV']}, QE_CONF_FOLDER={os.environ['QE_CONF_FOLDER']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sources.datamodel.listing_details import ListingDetails\n",
    "from sources.datamodel.listing_record import ListingRecord\n",
    "from sources.logging import logging_utils\n",
    "from sources.storage.abstract_storage import Storage\n",
    "from sources.config.config_manager import ConfigManager\n",
    "from sources.mappers.immobiliare_listing_mapper import ListingDataTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_utils.setup_logging(config_path=\"sources/resources/logging.yaml\")\n",
    "logger = logging_utils.get_logger(__name__)\n",
    "\n",
    "config_manager = ConfigManager()\n",
    "config_manager.invalidate_caches()\n",
    "\n",
    "storage_settings = config_manager.get_storage_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage: Storage = Storage.create_storage(\n",
    "    data_type=ListingRecord, \n",
    "    config=storage_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Extract ListingIds from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from sources.config.model.storage_settings import MongoStorageSettings\n",
    "from sources.storage.mongo_storage import MongoDBStorage\n",
    "\n",
    "\n",
    "# Get MongoDB configuration from storage settings\n",
    "mongo_config: MongoStorageSettings = storage_settings.mongodb_settings  # This should be a MongoStorageSettings instance\n",
    "\n",
    "\n",
    "# Connect to MongoDB using the same configuration as the storage\n",
    "@contextmanager\n",
    "def get_mongo_client():\n",
    "    \"\"\"Context manager for MongoDB client with proper resource cleanup.\"\"\"\n",
    "    client = MongoClient(mongo_config.connection_string.get_secret_value())\n",
    "    try:\n",
    "        yield client\n",
    "    finally:\n",
    "        client.close()\n",
    "\n",
    "\n",
    "# Query for ListingDetails that don't have corresponding ListingRecords using aggregation\n",
    "batch_size = 3000\n",
    "\n",
    "\n",
    "with get_mongo_client() as client:\n",
    "\n",
    "    db = client[mongo_config.database]\n",
    "    listings_collection = db[mongo_config.collection_listings]\n",
    "    records_collection = db[mongo_config.collection_records]\n",
    "\n",
    "    # Use aggregation pipeline with $lookup (left outer join) to find unprocessed IDs\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$lookup\": {\n",
    "                \"from\": mongo_config.collection_records,  # Join with records collection\n",
    "                \"localField\": \"id\",  # Field from listings collection\n",
    "                \"foreignField\": \"id\",  # Field from records collection\n",
    "                \"as\": \"listing_records\",  # Output array field\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$match\": {\n",
    "                \"listing_records\": {\n",
    "                    \"$size\": 0\n",
    "                }  # Filter where no matching listing records found\n",
    "            }\n",
    "        },\n",
    "        {\"$sample\": {\"size\": batch_size}},  # Randomly sample from matching documents\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"listing_records\": 0  # Remove the empty listing_records array from output\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute aggregation pipeline\n",
    "    unprocessed_docs = list(listings_collection.aggregate(pipeline))\n",
    "\n",
    "    # Convert documents back to ListingDetails objects\n",
    "    listingDetails = [ListingDetails.from_dict(doc) for doc in unprocessed_docs]\n",
    "\n",
    "    print(f\"Found {len(listingDetails)} ListingDetails without corresponding ListingRecords\")\n",
    "\n",
    "\n",
    "listingDetails[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = ListingDataTransformer()\n",
    "\n",
    "records = [mapper.map(listing) for listing in listingDetails]\n",
    "storage.append_data(records)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
